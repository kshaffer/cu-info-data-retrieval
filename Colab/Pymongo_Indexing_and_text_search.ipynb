{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# MongoDB/Pymongo Indexes and Text Search\n",
    "\n",
    "Work in driver/navigator pairs with a single laptop. Talk through each idea before you code so both partners understand the plan."
   ],
   "id": "4bfa8ff624a073d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Setup\n",
    "\n",
    "Import the core libraries we will need for HTTP requests, JSON inspection, and quick analyses."
   ],
   "id": "a96d593020608cfe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pymongo import MongoClient\n",
    "from pprint import pprint"
   ],
   "id": "44fd0641e59edcec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Retrieve posts from your local MongoDB database",
   "id": "dda8adcb36e53371"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# create database connection\n",
    "client = MongoClient()\n",
    "db = client.mastodon_test\n",
    "db"
   ],
   "id": "fd54c906d322ed68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# show collections in mastodon_test\n",
    "db.list_collection_names()"
   ],
   "id": "b89dead190d485b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# assign variable to collection in mastodon_test\n",
    "coll = ...\n",
    "coll"
   ],
   "id": "4a34422e20f966cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# confirm number of documents\n",
    "coll..."
   ],
   "id": "1b7e5266f970193d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# show a sample post from the collection\n",
    "sample = ...\n",
    "pprint(sample)"
   ],
   "id": "6ecd48e736552ab5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. .explain()",
   "id": "2daf66d1da794cca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Start by using explain to see what MongoDB does in a basic .find() query.\n",
    "exp = coll.find({}).explain()\n",
    "pprint(exp)"
   ],
   "id": "105451523a0a66ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Copy this output and paste it into ChatGPT, Claude, or Gemini, and ask it to explain what it sees in plain English, noting any indexes it sees and is using.",
   "id": "8a5055350b404161"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Things are funky in Pymongo when we're dealing with aggregation queries, though. _More complicated than in your reading on MongoDB!_ Let's unpack this with a pipeline aggregation query from last week's notebook.",
   "id": "c5ff002cbd5f558e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pipeline = [\n",
    "    {'$unwind': '$tags'},\n",
    "    {'$project': {\n",
    "        '_id': 0,\n",
    "        'acct': '$account.acct',\n",
    "        'created_at': 1,\n",
    "        'hashtag': '$tags.name'\n",
    "    }},\n",
    "    {'$group': {\n",
    "        '_id': '$hashtag',\n",
    "        'count': {'$sum': 1}\n",
    "    }},\n",
    "    {'$sort': {'count': -1}},\n",
    "    {'$limit': 10}\n",
    "]\n",
    "\n",
    "result = coll.aggregate(pipeline)\n",
    "for doc in result:\n",
    "    pprint(doc)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If we do what we did above with the .find() query, it won't work.",
   "id": "1e02e9bc7a035c2f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "exp = coll.aggregate(pipeline).explain()\n",
    "pprint(exp)"
   ],
   "id": "afe72810aed4a76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here's how we have to do it. (Hang onto this code so you can reuse it in the future.)",
   "id": "fc61fead43669e3b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plan = coll.database.command(\n",
    "    \"explain\",\n",
    "    {\n",
    "        \"aggregate\": coll.name,\n",
    "        \"pipeline\": pipeline,\n",
    "        \"cursor\": {}\n",
    "    },\n",
    "    verbosity=\"executionStats\"  # âœ… accepted here\n",
    ")\n",
    "\n",
    "pprint(plan)"
   ],
   "id": "3fc3fa21e49b1468",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now copy that output, paste it into an AI chat, and ask it to explain it in plain English, specifically referencing any indexes it finds.",
   "id": "30f1fe7d5035acb1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# now take ANY .aggregate() query from last week's notebook, run .explain() on it, and ask an AI chat to explain it in plain English.\n",
    "\n",
    "..."
   ],
   "id": "24bf71417363c3cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Standard indexes",
   "id": "2637041a65bb28aa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's practice indexing with the account.acct field for faster account searching.",
   "id": "b2b3210665f1eda7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Pick a username from your database\n",
    "\n",
    "username = coll.find_one()['account']['acct']\n",
    "print(username)"
   ],
   "id": "6dcee8acf270671e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# search for all posts from that user and run .explain()\n",
    "# Use AI (or your own eyes -- look at 'winningPlan', do you see 'COLLSCAN'?) to ensure that it is not using any indexes\n",
    "\n",
    "posts = ...\n",
    "pprint(posts.explain())"
   ],
   "id": "1672945bb8f502af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# now let's index that field\n",
    "\n",
    "coll.create_index([(\"account.acct\", 1)],\n",
    "                  name=\"acct_index\") # name optional, but can help debug"
   ],
   "id": "4d1df61e91b0f9b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# rerun your explain and explore the output to ensure the index is being used\n",
    "# use AI to help analyze your output if necessary (or just look for 'winningPlan' -- do you see an index? named acct_index?)\n",
    "\n",
    "posts = ...\n",
    "pprint(posts.explain())"
   ],
   "id": "fc9d1ec059c60ca9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now let's do one on followers_count. Since we'll typically be looking for accounts with the MOST followers, we'll want the index in DESCENDING order.",
   "id": "b18c927e87d17e65"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# first, run a find query that identifies the 10 posts (not accounts!) with the most followers, and add .explain().\n",
    "# what method is it using?\n",
    "\n",
    "exp = coll.find({}).sort('followers_count', -1).limit(10).explain()\n",
    "\n",
    "pprint(exp)"
   ],
   "id": "85b6cd327f9a39b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# now add a DESCENDING index on that field\n",
    "\n",
    "..."
   ],
   "id": "6637e2bbe7ff8bea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# rerun the explain to ensure the index is being used\n",
    "\n",
    "exp = coll.find({}).sort('followers_count', -1).limit(10).explain()\n",
    "\n",
    "pprint(exp)"
   ],
   "id": "3e333505d170aad9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Array indexes",
   "id": "c4c8173fd4ec3882"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To index every element in an array (like tags or media_attachments), just create an index on that field. MongoDB will automatically index each element in the arrays. Note, though, that these indexes will be more \"expensive\" (take up more space, add more time when adding new documents) than one that indexes one element per document (like account.acct or content).",
   "id": "6ba3615ce3fb3e39"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# grab the grouping query from last week's notebook that returns the top 10 hashtags (there were two, either one is fine). Run just that query.\n",
    "\n",
    "pipeline = [\n",
    "    {'$unwind': '$tags'},\n",
    "    {'$group': {\n",
    "        '_id': '$tags.name',\n",
    "        'count': {'$sum': 1}\n",
    "    }},\n",
    "    {'$sort': {'count': -1}},\n",
    "    {'$limit': 10}\n",
    "]\n",
    "\n",
    "result = coll.aggregate(pipeline)\n",
    "for doc in result:\n",
    "    pprint(doc)"
   ],
   "id": "775f95a9fe4ba7c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# now run explain() on this query (remember that aggregate requires a more involved method, but you can just copy and paste from above).\n",
    "# This output will be more complicated, so you may want to use AI to help explain it to you and check for index usage.\n",
    "\n",
    "plan = ...\n",
    "\n",
    "pprint(plan)"
   ],
   "id": "6619ae34656d7d09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# now add an index to the hashtag name field, ascending is fine.\n",
    "\n",
    "..."
   ],
   "id": "61cd8812f1955c8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# now rerun the above explain to ensure the index is being used.\n",
    "\n",
    "plan = ...\n",
    "\n",
    "pprint(plan)"
   ],
   "id": "b766f36bf89078d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# let's check a simple hashtag search to see if it uses the index\n",
    "\n",
    "coll.find({'tags.name': 'nature'}).explain()"
   ],
   "id": "8e3ddf0ea7594584",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Text indexes and searches",
   "id": "1ab8bbcef1d5c91"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To perform a keyword or partial text search (like SQL's `WHERE content like '%keyword%'`), we need to use `$regex`.",
   "id": "b425c4a53fe141eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# perform a search for the word 'nature' somewhere in the post content\n",
    "\n",
    "cursor = coll.find({'content': { '$regex': 'nature'}})\n",
    "\n",
    "for post in cursor:\n",
    "    pprint(post['content'])"
   ],
   "id": "8a585e1de3a9039f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# add `$options: 'i'` to make it case-insensitive\n",
    "\n",
    "cursor = coll.find({'content': { '$regex': 'nature',\n",
    "                                 '$options': 'i'}})\n",
    "\n",
    "for post in cursor:\n",
    "    pprint(post['content'])"
   ],
   "id": "bf169f657ec9c546",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For the most robust text searches in MongoDB, we'd have to use their Atlas platform. Most significant is that Atlas is required to do partial-word matches with wildcards. However, as long as we're doing full-word searches, we can run that locally, and we can create a text index to support it.",
   "id": "365a0820210c3eb8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# first, run the above search with .explain() to see it without an index\n",
    "\n",
    "exp = coll.find({'content': { '$regex': 'nature',\n",
    "                              '$options': 'i'}})\n",
    "\n",
    "pprint(exp.explain())"
   ],
   "id": "3bb65d42ecc7523e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# now create a TEXT index on content\n",
    "# note the import statement -- you only need to do that once\n",
    "# Also note the default_language and language_override fields. This is because Mastodon includes a language field, but it's not always populated, so MongoDB gets confused trying to decide what language(s) to use to support some of their advanced language parsing features. Just use this code if you want to avoid that problem with this data.\n",
    "\n",
    "from pymongo import TEXT\n",
    "\n",
    "coll.create_index([(\"content\", TEXT)],\n",
    "                  name=\"content_text_index\",\n",
    "                  default_language=\"english\",\n",
    "                  language_override=\"__no_override__\"\n",
    "                  )"
   ],
   "id": "c9a33671d1c36833",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# now rerun the above keyword search to ensure the index is being used\n",
    "\n",
    "exp = coll.find({'content': { '$regex': 'nature'}})\n",
    "\n",
    "pprint(exp.explain())"
   ],
   "id": "d7720dbab349f93d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# $regex doesn't work with the TEXT index we created. We have to do the text search a little differently. (This method ONLY works with a TEXT index.)\n",
    "# Again, just copy and paste this code, modifying as necessary, for future projects, including the midterm.\n",
    "\n",
    "cursor = coll.find(\n",
    "    {\"$text\": {\"$search\": \"nature\"}},\n",
    "    {\"content\": 1}\n",
    ")\n",
    "\n",
    "pprint(cursor.explain())"
   ],
   "id": "743c32982697d234",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Now let's use it in an aggregation pipeline.\n",
    "# Perform the same search as a $match, then return the three matching posts with the highest followers_count.\n",
    "# Return only the content and followers_count fields.\n",
    "\n",
    "pipeline = [\n",
    "    ...\n",
    "]\n",
    "\n",
    "cursor = coll.aggregate(pipeline)\n",
    "\n",
    "for doc in cursor:\n",
    "    pprint(doc)"
   ],
   "id": "c1570ca32948f5c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Now run that same pipeline with explain to see if it's using the text index.\n",
    "# By the way, ... is it using the followers_count index? Why or why not?\n",
    "\n",
    "plan = ...\n",
    "\n",
    "pprint(plan)"
   ],
   "id": "d10def304aa77874",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Save this file WITH ALL OUTPUT SHOWING and submit to Canvas",
   "id": "135de5e2821b9203"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
