{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Embeddings with Sentence Transformers",
   "id": "f321c7012472706d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Install any packages you don't already have.",
   "id": "9988b08ca7fe166f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "!pip install sentence_transformers\n",
    "!pip install pymongo"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from nltk.tokenize import sent_tokenize\n"
   ],
   "id": "f87a51d29839a9bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Import a semantic sentence model, against which you will calculate embeddings. There are MANY to choose from. We'll start with a lightweight, all-purpose model suggested by our reading, `all-MiniLM-L6-v2`. I've also preloaded code here for a much more robust multilingual model that I like to use for narrative discovery and translation tasks, `LaBSE`. But there are many more out there...",
   "id": "4250fed9b1b70c39"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# a good, lightweight model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# a better but much larger model, LaBSE\n",
    "# model = SentenceTransformer('sentence-transformers/LaBSE')"
   ],
   "id": "4700098a2d912815",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's read in some documents and generate embeddings for them that align with the chosen model.",
   "id": "741d825305ec92af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open('turing.txt') as f:\n",
    "    text = f.read()\n",
    "\n",
    "en_sents = sent_tokenize(text.replace('\\t', ' ').replace('\\n', ' ').replace('“', '\"').replace('”', '\"').replace('. . . .', '....').replace(' . . .', '...').replace('. . .', '...'))\n",
    "en_sents = [sent.replace('\\n', ' ') for sent in en_sents]\n",
    "\n",
    "with open('turing_sentences.txt', 'w') as f:\n",
    "    for sent in en_sents:\n",
    "        f.write(sent + '\\n')"
   ],
   "id": "44199bb92df7f95a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# read in some documents from facts.txt\n",
    "with open('turing_sentences.txt', 'r') as f:\n",
    "    documents = f.readlines()\n",
    "    documents = [x.strip() for x in documents]"
   ],
   "id": "142bc999b55b77b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(documents)",
   "id": "7bb76b4bb2f68618",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "embeddings = model.encode(documents)",
   "id": "32a72cc0e5ec633d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# print the number of dimensions in these embeddings\n",
    "print(len(embeddings[0]))\n",
    "\n",
    "# print the embedding of the first sentence\n",
    "embeddings[0]"
   ],
   "id": "28b57889036cae16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# show all of the embeddings\n",
    "embeddings"
   ],
   "id": "6dacca26fa5483c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now let's use MongoDB's native vector search capabilities. As of September 2025, MongoDB Community Edition supports vector search locally!",
   "id": "7fac3eca624f2778"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Connect to MongoDB (local installation)\n",
    "client = MongoClient('mongodb://localhost:50085/?directConnection=true')\n",
    "db = client['turing']\n",
    "collection = db['sentences']\n",
    "\n",
    "# Clear any existing documents\n",
    "collection.delete_many({})\n",
    "print(\"Connected to MongoDB\")"
   ],
   "id": "d74c6d61f3f440ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Store documents and embeddings in MongoDB\ndocs_to_insert = []\nfor i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n    docs_to_insert.append({\n        'text': doc,\n        'embedding': embedding.tolist()\n    })\n\nresult = collection.insert_many(docs_to_insert)\nprint(f\"Inserted {len(result.inserted_ids)} documents into MongoDB\")",
   "id": "20dea292ade57538",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "collection.find_one()",
   "id": "49c049359ba4631e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "tr0yj905ru",
   "source": [
    "# Create a vector search index\n",
    "# This enables efficient vector similarity search in MongoDB\n",
    "try:\n",
    "    collection.create_search_index(\n",
    "        model={\n",
    "            \"definition\": {\n",
    "                \"mappings\": {\n",
    "                    \"dynamic\": True,\n",
    "                    \"fields\": {\n",
    "                        \"embedding\": {\n",
    "                            \"type\": \"vector\",\n",
    "                            \"numDimensions\": 384,\n",
    "                            \"similarity\": \"cosine\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"name\": \"vector_index\"\n",
    "        }\n",
    "    )\n",
    "    print(\"Vector search index created successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Index creation note: {e}\")\n",
    "    print(\"Index may already exist or require MongoDB 7.0+ with vector search enabled\")"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now let's ask a question of this database.",
   "id": "6261f2d3d1b8f11"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Try another question\n",
    "query = 'Who was Alan Turing?'\n",
    "query_embedding = model.encode(query)\n",
    "\n",
    "pipeline = [\n",
    "    {\n",
    "        \"$vectorSearch\": {\n",
    "            \"index\": \"vector_index\",\n",
    "            \"path\": \"embedding\",\n",
    "            \"queryVector\": query_embedding.tolist(),\n",
    "            \"numCandidates\": 100,\n",
    "            \"limit\": 5\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$project\": {\n",
    "            \"_id\": 0,\n",
    "            \"text\": 1,\n",
    "            \"score\": {\"$meta\": \"vectorSearchScore\"}\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "results = list(collection.aggregate(pipeline))\n",
    "\n",
    "for result in results:\n",
    "    print(result['text'])"
   ],
   "id": "f3c3a04bb3748dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a09c66016a2dd38c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
