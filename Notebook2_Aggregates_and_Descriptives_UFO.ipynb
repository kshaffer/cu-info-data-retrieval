{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1163154f",
   "metadata": {},
   "source": [
    "# Notebook 2 ‚Äî Aggregates & Descriptives (UFO)\n",
    "\n",
    "_INFO 4614 ‚Ä¢ Unit 1: Relational Databases (MySQL)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb315d9",
   "metadata": {},
   "source": [
    "**Builds on Notebook 1.** We'll stay in Python + SQL, now focusing on **aggregates** and **descriptive summaries** without joins:\n",
    "- `COUNT`, `COUNT(DISTINCT ...)`, `MIN`, `MAX`, `AVG`, `SUM`\n",
    "- `GROUP BY` and `HAVING`\n",
    "- Handling **NULLs** with `COALESCE` / `IFNULL`\n",
    "- Light **string** and **date/time** helpers for grouping (e.g., `LOWER`, `TRIM`, `STR_TO_DATE`, `YEAR`)\n",
    "\n",
    "**Dataset.** Database **`ufo`**, table **`sightings`** (structure mirrors `ufo_scrubbed.csv`).\n",
    "\n",
    "> Tip: You can copy your working connection code from **Notebook 1**. The cells below also provide a clean setup if you prefer to start fresh."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1705be",
   "metadata": {},
   "source": [
    "**Submission checklist**\n",
    "\n",
    "- ‚úÖ All cells run top‚Äìto‚Äìbottom without errors\n",
    "- ‚úÖ Every **Exercise** cell is filled in and produces an output\n",
    "- ‚úÖ Results appear as DataFrames (and optional plots if you do the stretch goal)\n",
    "- ‚úÖ File is renamed `Notebook2_LastFirst.ipynb` before submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e120d7aa",
   "metadata": {},
   "source": [
    "## 0) Setup & connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2234e80e",
   "metadata": {},
   "source": [
    "We'll install dependencies (same as Notebook 1), set connection variables for the **UFO** database, and ensure **TLS** using the Amazon RDS **global CA** (`global-bundle.pem`).\n",
    "\n",
    "‚ö†Ô∏è **Quoting column names with spaces.** In this table, some columns have spaces or punctuation (e.g., ``duration (seconds)``, ``longitude `` has a trailing space). In MySQL, use **backticks** to quote such identifiers: ``SELECT `duration (seconds)` FROM sightings``. You can also use `AS` to assign cleaner output names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ed2f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install light dependencies (same as Notebook 1)\n",
    "!pip -q install mysql-connector-python SQLAlchemy pandas matplotlib\n",
    "\n",
    "# Versions\n",
    "import sys, sqlalchemy, pandas\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"SQLAlchemy:\", sqlalchemy.__version__)\n",
    "print(\"pandas:\", pandas.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002f34df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection settings (same host/port as Notebook 1; different DB name)\n",
    "DB_HOST = \"info4614.c7kemoi0y6yq.us-east-2.rds.amazonaws.com\"\n",
    "DB_PORT = 3306\n",
    "DB_NAME = \"ufo\"\n",
    "\n",
    "CA_CERT_PATH = \"global-bundle.pem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bc385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the current Amazon RDS global certificate bundle (TLS)\n",
    "!wget -q https://truststore.pki.rds.amazonaws.com/global/global-bundle.pem -O \"$CA_CERT_PATH\"\n",
    "\n",
    "import os\n",
    "assert os.path.exists(CA_CERT_PATH), \"PEM download failed ‚Äî re-run or upload manually\"\n",
    "print(\"Saved:\", os.path.abspath(CA_CERT_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca93a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: upload a PEM you already have\n",
    "# (Skip if the previous cell succeeded)\n",
    "try:\n",
    "    from google.colab import files\n",
    "    print(\"Upload global-bundle.pem if needed\")\n",
    "    uploaded = files.upload()\n",
    "except Exception as e:\n",
    "    print(\"Upload not available here:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507989a1",
   "metadata": {},
   "source": [
    "### Enter your read‚Äëonly credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8daf232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "DB_USER = input(\"MySQL username: \").strip()\n",
    "DB_PASS = getpass(\"MySQL password: \").strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19179b51",
   "metadata": {},
   "source": [
    "### Create SQLAlchemy engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1576364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "engine = create_engine(\n",
    "    f\"mysql+mysqlconnector://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\",\n",
    "    connect_args={\"ssl_ca\": CA_CERT_PATH},\n",
    "    pool_pre_ping=True,\n",
    ")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    print(\"SELECT 1 ‚Üí\", conn.execute(text(\"SELECT 1\")).scalar_one())\n",
    "    cipher = conn.execute(text(\"SHOW SESSION STATUS LIKE 'Ssl_cipher'\")).fetchone()\n",
    "    print(\"SSL cipher:\", cipher[1] if cipher else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffd40bc",
   "metadata": {},
   "source": [
    "## 1) Quick schema check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd60b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    print(\"Tables:\")\n",
    "    display(pd.read_sql_query(\"SHOW TABLES\", conn))\n",
    "\n",
    "    print(\"\\n`ufo.sightings` definition:\")\n",
    "    display(pd.read_sql_query(\"DESCRIBE sightings\", conn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c607ca34",
   "metadata": {},
   "source": [
    "## 2) Aggregates and GROUP BY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b5e7f2",
   "metadata": {},
   "source": [
    "We‚Äôll start with counts and then layer on more aggregate functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff394f01",
   "metadata": {},
   "source": [
    "### 2.1 Overall row count + distincts\n",
    "- Total number of sightings\n",
    "- Number of **distinct** `shape` values\n",
    "- Number of **distinct** `country` values\n",
    "\n",
    "Return a single row with three columns: `total_rows`, `distinct_shapes`, `distinct_countries`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c423050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Exercise 2.1\n",
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT\n",
    "  COUNT(*)            AS total_rows,\n",
    "  COUNT(DISTINCT shape)   AS distinct_shapes,\n",
    "  COUNT(DISTINCT country) AS distinct_countries\n",
    "FROM sightings;\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    df_counts = pd.read_sql_query(text(sql), conn)\n",
    "\n",
    "df_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fad1870",
   "metadata": {},
   "source": [
    "### 2.2 Top shapes by count\n",
    "List the **top 10 shapes** (by number of rows), with columns `shape`, `n`. Exclude NULL/empty shapes.\n",
    "\n",
    "**Hints:** `WHERE shape IS NOT NULL AND shape <> ''`, `GROUP BY shape`, `ORDER BY n DESC`, `LIMIT 10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43efd132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Exercise 2.2\n",
    "sql = \"\"\"\n",
    "SELECT\n",
    "  shape,\n",
    "  COUNT(*) AS n\n",
    "FROM sightings\n",
    "WHERE ...\n",
    "GROUP BY ...\n",
    "ORDER BY ...\n",
    "LIMIT ...\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    df_shapes = pd.read_sql_query(text(sql), conn)\n",
    "\n",
    "df_shapes.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c86a53",
   "metadata": {},
   "source": [
    "### 2.3 U.S. states with the most reports\n",
    "Filter to U.S. sightings (`country = 'us'`), group by `state`, and return the **top 15** states with the most reports.\n",
    "Only include non‚ÄëNULL/non‚Äëempty states.\n",
    "\n",
    "Columns: `state`, `n`. Sorted by `n` descending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de45930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Exercise 2.3\n",
    "sql = \"\"\"\n",
    "SELECT\n",
    "  state,\n",
    "  COUNT(*) AS n\n",
    "FROM sightings\n",
    "WHERE ...\n",
    "GROUP BY ...\n",
    "ORDER BY ...\n",
    "LIMIT ...\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    df_states = pd.read_sql_query(text(sql), conn)\n",
    "\n",
    "df_states.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f26352",
   "metadata": {},
   "source": [
    "## 3) Averages, mins/maxes, and HAVING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20dfb82",
   "metadata": {},
   "source": [
    "We‚Äôll use the numeric column `` `duration (seconds)` `` and compute summaries by group. Use `HAVING` to filter **after** aggregation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d04847",
   "metadata": {},
   "source": [
    "### 3.1 Average duration by shape\n",
    "Compute `AVG(\\`duration (seconds)\\`)` by `shape`. Return columns:\n",
    "`shape`, `avg_seconds`, `n` (count per shape).\n",
    "\n",
    "Sort by `avg_seconds` descending. Include only shapes with at least **30** sightings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e1182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Exercise 3.1\n",
    "sql = \"\"\"\n",
    "SELECT\n",
    "  shape,\n",
    "  AVG(`duration (seconds)`) AS avg_seconds,\n",
    "  COUNT(*)                  AS n\n",
    "FROM sightings\n",
    "GROUP BY ...\n",
    "HAVING ...\n",
    "ORDER BY ...\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    df_avg_shape = pd.read_sql_query(text(sql), conn)\n",
    "\n",
    "df_avg_shape.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8118b7c",
   "metadata": {},
   "source": [
    "### 3.2 Min/Max sanity check\n",
    "For the same groups (by `shape`), compute `MIN`, `MAX`, and a **rounded** average (to 1 decimal).\n",
    "\n",
    "Columns: `shape, min_s, max_s, avg_s_rounded, n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a846028e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Exercise 3.2\n",
    "sql = \"\"\"\n",
    "SELECT\n",
    "  shape,\n",
    "  MIN(`duration (seconds)`)              AS min_s,\n",
    "  MAX(`duration (seconds)`)              AS max_s,\n",
    "  ROUND(AVG(`duration (seconds)`), 1)    AS avg_s_rounded,\n",
    "  COUNT(*)                               AS n\n",
    "FROM sightings\n",
    "GROUP BY ...\n",
    "HAVING ...\n",
    "ORDER BY ...\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    df_minmax = pd.read_sql_query(text(sql), conn)\n",
    "\n",
    "df_minmax.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa63f5d6",
   "metadata": {},
   "source": [
    "## 4) Handling NULL/empty and simple string helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef682e10",
   "metadata": {},
   "source": [
    "We'll group on a **filled** state value using `COALESCE`. Example pattern:\n",
    "\n",
    "```sql\n",
    "COALESCE(NULLIF(TRIM(state), ''), 'UNKNOWN')\n",
    "```\n",
    "\n",
    "That treats whitespace/empty strings as NULL and replaces missing with `'UNKNOWN'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bda67a",
   "metadata": {},
   "source": [
    "### 4.1 U.S. counts with UNKNOWN bucket\n",
    "Group U.S. sightings by a cleaned state bucket using the `COALESCE(NULLIF(TRIM(state), ''), 'UNKNOWN')` pattern.\n",
    "Return columns: `state_bucket`, `n`, sorted by `n` desc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681aa6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Exercise 4.1\n",
    "sql = \"\"\"\n",
    "SELECT\n",
    "  COALESCE(NULLIF(TRIM(state), ''), 'UNKNOWN') AS state_bucket,\n",
    "  COUNT(*) AS n\n",
    "FROM sightings\n",
    "WHERE country = 'us'\n",
    "GROUP BY ...\n",
    "ORDER BY ...\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    df_state_bucket = pd.read_sql_query(text(sql), conn)\n",
    "\n",
    "df_state_bucket.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da52d269",
   "metadata": {},
   "source": [
    "## 5) Light date/time derived columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc3a237",
   "metadata": {},
   "source": [
    "The `datetime` column is stored as text in the form `MM/DD/YYYY HH:MM`. MySQL can parse it with `STR_TO_DATE`.\n",
    "We'll extract **year** to see long‚Äëterm patterns.\n",
    "\n",
    "Format string: `'%m/%d/%Y %H:%i'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fed07e",
   "metadata": {},
   "source": [
    "### 5.1 Sightings per year (top 15 years)\n",
    "Create a derived column `yr` with `YEAR(STR_TO_DATE(\\`datetime\\`, '%m/%d/%Y %H:%i'))` and count rows per year.\n",
    "Sort by count desc and show the **top 15** rows.\n",
    "\n",
    "Columns: `yr`, `n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63e38ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Exercise 5.1\n",
    "sql = \"\"\"\n",
    "SELECT\n",
    "  YEAR(STR_TO_DATE(`datetime`, '%m/%d/%Y %H:%i')) AS yr,\n",
    "  COUNT(*) AS n\n",
    "FROM sightings\n",
    "GROUP BY ...\n",
    "ORDER BY ...\n",
    "LIMIT ...\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    df_years = pd.read_sql_query(text(sql), conn)\n",
    "\n",
    "df_years.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08025886",
   "metadata": {},
   "source": [
    "### 5.2 Average duration by year (filter with HAVING)\n",
    "Using the same `yr` expression, compute the average duration per year where there are at least **100** records in that year.\n",
    "Return `yr`, `avg_seconds`, `n` ordered by `yr` ascending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae836e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Exercise 5.2\n",
    "sql = \"\"\"\n",
    "SELECT\n",
    "  YEAR(STR_TO_DATE(`datetime`, '%m/%d/%Y %H:%i')) AS yr,\n",
    "  AVG(`duration (seconds)`) AS avg_seconds,\n",
    "  COUNT(*) AS n\n",
    "FROM sightings\n",
    "GROUP BY ...\n",
    "HAVING ...\n",
    "ORDER BY ...\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    df_avg_by_year = pd.read_sql_query(text(sql), conn)\n",
    "\n",
    "df_avg_by_year.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b92b7c",
   "metadata": {},
   "source": [
    "## 6) Light pandas (inspect + simple viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137ff005",
   "metadata": {},
   "source": [
    "We'll keep pandas simple. Convert one of your SQL results into a small **bar chart**.\n",
    "\n",
    "> If plotting causes issues, skip the plot and just show the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3342ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of top shapes (from Exercise 2.2)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_shapes_plot = df_shapes.copy().head(10)\n",
    "df_shapes_plot.plot(kind=\"bar\", x=\"shape\", y=\"n\", legend=False, title=\"Top 10 UFO shapes by count\")\n",
    "plt.xlabel(\"shape\"); plt.ylabel(\"count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7611232",
   "metadata": {},
   "source": [
    "## (Optional) Fallback: local CSV (pandas only)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11842979",
   "metadata": {},
   "source": [
    "If you need to test without a DB connection, you can upload `ufo_scrubbed.csv` and practice the pandas parts.\n",
    "This does **not** replace the requirement to connect to the database for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380e9019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "try:\n",
    "    from google.colab import files\n",
    "    print(\"Upload ufo_scrubbed.csv\")\n",
    "    uploaded = files.upload()\n",
    "    csv_name = next(iter(uploaded.keys()))\n",
    "    ufo_csv = pd.read_csv(csv_name)\n",
    "    ufo_csv.head()\n",
    "except Exception as e:\n",
    "    print(\"Upload not available here:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec47ff83",
   "metadata": {},
   "source": [
    "## Troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6bf2d2",
   "metadata": {},
   "source": [
    "- **`Access denied ...` (1045)** ‚Üí Check your read‚Äëonly username/password and ask the instructor if needed.\n",
    "- **Timeout / can‚Äôt connect (2003)** ‚Üí Network or RDS SG issue. Try campus Wi‚ÄëFi or VPN; ask the instructor to whitelist your IP if necessary.\n",
    "- **`ssl ca certificate` errors** ‚Üí Re‚Äërun the PEM download cell or upload the correct `global-bundle.pem` and ensure `connect_args={\"ssl_ca\": \"global-bundle.pem\"}`.\n",
    "- **SQL errors** ‚Üí Check backticks around columns with spaces or punctuation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa696b0",
   "metadata": {},
   "source": [
    "## Submit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49008014",
   "metadata": {},
   "source": [
    "- **Runtime ‚Üí Restart and run all** to confirm a clean run\n",
    "- **File ‚Üí Download .ipynb**, rename to `Notebook2_LastFirst.ipynb`, and submit as directed"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
