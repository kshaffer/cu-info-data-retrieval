{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1163154f",
   "metadata": {},
   "source": [
    "# Notebook 2 â€” Aggregates & Descriptives (UFO)\n",
    "\n",
    "_INFO 4614 â€¢ Unit 1: Relational Databases (MySQL)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb315d9",
   "metadata": {},
   "source": [
    "**Builds on Notebook 1.** We'll stay in Python + SQL and frame everything as **research questions**, then translate those questions into queries. No joins yet.\n",
    "\n",
    "We focus on:\n",
    "- Aggregates: `COUNT`, `COUNT(DISTINCT ...)`, `MIN`, `MAX`, `AVG`, `SUM`\n",
    "- `GROUP BY` and `HAVING`\n",
    "- Handling **NULLs** with `COALESCE` / `IFNULL`\n",
    "- Light **string** and **date/time** helpers for grouping (e.g., `LOWER`, `TRIM`, `STR_TO_DATE`, `YEAR`)\n",
    "\n",
    "**Dataset.** Database **`ufo`**, table **`sightings`** (structure mirrors `ufo_scrubbed.csv`).\n",
    "\n",
    "> Tip: Copy your working connection cell from **Notebook 1** or use the setup below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1705be",
   "metadata": {},
   "source": [
    "**Submission checklist**\n",
    "\n",
    "- âœ… All cells run topâ€“toâ€“bottom without errors\n",
    "- âœ… Every **Exercise** cell is filled in and produces an output\n",
    "- âœ… Results appear as DataFrames (and optional plots if you do the stretch goal)\n",
    "- âœ… File is renamed `Notebook2_LastFirst.ipynb` before submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e120d7aa",
   "metadata": {},
   "source": [
    "## 0) Setup & connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2234e80e",
   "metadata": {},
   "source": [
    "We'll install dependencies (same as Notebook 1), set connection variables for the **UFO** database, and ensure **TLS** using the Amazon RDS **global CA** (`global-bundle.pem`).\n",
    "\n",
    "**Quoting column names with spaces.** If a column name has spaces or punctuation (e.g., ``duration (seconds)``), use **backticks** in MySQL: ``SELECT `duration (seconds)` FROM sightings``. You can also use `AS` to assign cleaner output names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ed2f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install light dependencies (same as Notebook 1)\n",
    "!pip -q install mysql-connector-python SQLAlchemy pandas matplotlib\n",
    "\n",
    "# Versions\n",
    "import sys, sqlalchemy, pandas\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"SQLAlchemy:\", sqlalchemy.__version__)\n",
    "print(\"pandas:\", pandas.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002f34df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection settings (same host/port as Notebook 1; different DB name)\n",
    "DB_HOST = \"info4614.c7kemoi0y6yq.us-east-2.rds.amazonaws.com\"\n",
    "DB_PORT = 3306\n",
    "DB_NAME = \"ufo\"\n",
    "\n",
    "CA_CERT_PATH = \"global-bundle.pem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bc385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the current Amazon RDS global certificate bundle (TLS)\n",
    "!wget -q https://truststore.pki.rds.amazonaws.com/global/global-bundle.pem -O \"$CA_CERT_PATH\"\n",
    "\n",
    "import os\n",
    "assert os.path.exists(CA_CERT_PATH), \"PEM download failed â€” re-run or upload manually\"\n",
    "print(\"Saved:\", os.path.abspath(CA_CERT_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca93a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: upload a PEM you already have\n",
    "# (Skip if the previous cell succeeded)\n",
    "try:\n",
    "    from google.colab import files\n",
    "    print(\"Upload global-bundle.pem if needed\")\n",
    "    uploaded = files.upload()\n",
    "except Exception as e:\n",
    "    print(\"Upload not available here:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507989a1",
   "metadata": {},
   "source": [
    "### Enter your readâ€‘only credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8daf232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "DB_USER = input(\"MySQL username: \").strip()\n",
    "DB_PASS = getpass(\"MySQL password: \").strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19179b51",
   "metadata": {},
   "source": [
    "### Create SQLAlchemy engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1576364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "engine = create_engine(\n",
    "    f\"mysql+mysqlconnector://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\",\n",
    "    connect_args={\"ssl_ca\": CA_CERT_PATH},\n",
    "    pool_pre_ping=True,\n",
    ")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    print(\"SELECT 1 â†’\", conn.execute(text(\"SELECT 1\")).scalar_one())\n",
    "    cipher = conn.execute(text(\"SHOW SESSION STATUS LIKE 'Ssl_cipher'\")).fetchone()\n",
    "    print(\"SSL cipher:\", cipher[1] if cipher else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffd40bc",
   "metadata": {},
   "source": [
    "## 1) Quick schema check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd60b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    print(\"Tables:\")\n",
    "    display(pd.read_sql_query(\"SHOW TABLES\", conn))\n",
    "\n",
    "    print(\"\\n`ufo.sightings` definition:\")\n",
    "    display(pd.read_sql_query(\"DESCRIBE sightings\", conn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b29a9",
   "metadata": {},
   "source": [
    "\n",
    "## From research question â†’ SQL query (mini recipe)\n",
    "\n",
    "When you turn a research question into SQL, think in this order:\n",
    "\n",
    "1. **What rows do I need?** â†’ `FROM ... WHERE ...`\n",
    "2. **What is the unit of analysis?** â†’ columns in `GROUP BY` (or no grouping if a single summary)\n",
    "3. **What measurements per group?** â†’ aggregates like `COUNT(*)`, `AVG(x)`, `MIN/MAX`\n",
    "4. **Which groups qualify?** â†’ `HAVING` (filters *after* grouping), e.g., `HAVING COUNT(*) >= 30`\n",
    "5. **How should results be presented?** â†’ `ORDER BY ...`, `LIMIT ...`\n",
    "6. **Any cleanup?** â†’ `COALESCE(...)` for NULLs, `TRIM(...)` for stray whitespace, aliases with `AS`\n",
    "\n",
    "We'll practice this repeatedly:\n",
    "- Start with a **question**\n",
    "- Write the **SQL pattern**\n",
    "- Fill in the **code cell** to get a pandas DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c607ca34",
   "metadata": {},
   "source": [
    "## 2) Aggregates and GROUP BY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b5e7f2",
   "metadata": {},
   "source": [
    "Weâ€™ll start with counts and then layer on more aggregate functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff394f01",
   "metadata": {},
   "source": [
    "### RQ 1 â€” How big is this dataset? How diverse are shapes and countries?\n",
    "**Question.** *How many total reports are there? How many distinct shapes and countries are represented?*\n",
    "\n",
    "**Translate â†’ SQL.**\n",
    "- **Rows:** `FROM sightings`\n",
    "- **Measures:** `COUNT(*)`, `COUNT(DISTINCT shape)`, `COUNT(DISTINCT country)`\n",
    "- **Output:** one row with columns `total_rows`, `distinct_shapes`, `distinct_countries`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c423050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”§ Exercise 2.1\n",
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT\n",
    "  COUNT(*)            AS total_rows,\n",
    "  COUNT(DISTINCT shape)   AS distinct_shapes,\n",
    "  COUNT(DISTINCT country) AS distinct_countries\n",
    "FROM sightings;\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    df_counts = pd.read_sql_query(text(sql), conn)\n",
    "\n",
    "df_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fad1870",
   "metadata": {},
   "source": [
    "### RQ 2 â€” Which shapes get reported the most?\n",
    "**Question.** *What are the top 10 reported UFO shapes?*\n",
    "\n",
    "**Translate â†’ SQL.**\n",
    "- **Rows:** exclude NULL/empty `shape`\n",
    "- **Group:** by `shape`\n",
    "- **Measure:** `COUNT(*) AS n`\n",
    "- **Present:** `ORDER BY n DESC LIMIT 10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43efd132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”§ Exercise 2.2\n",
    "sql = \"\"\"\n",
    "SELECT\n",
    "  shape,\n",
    "  COUNT(*) AS n\n",
    "FROM sightings\n",
    "WHERE ...\n",
    "GROUP BY ...\n",
    "ORDER BY ...\n",
    "LIMIT ...\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    df_shapes = pd.read_sql_query(text(sql), conn)\n",
    "\n",
    "df_shapes.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecaed91",
   "metadata": {},
   "source": [
    "**ðŸ“ Interpretation (1â€“2 sentences).** In plain English, answer the research question above based on your result. \n",
    "\n",
    "- Mention any pattern or outlier you see.\n",
    "- If relevant, note one limitation (e.g., small group sizes, missing data).\n",
    "\n",
    "*Type your short answer here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c86a53",
   "metadata": {},
   "source": [
    "### RQ 3 â€” Which U.S. states have the most sightings?\n",
    "**Question.** *Among U.S. reports, which states have the highest counts?*\n",
    "\n",
    "**Translate â†’ SQL.**\n",
    "- **Rows:** `WHERE country = 'us'` and nonâ€‘NULL/nonâ€‘empty `state`\n",
    "- **Group:** by `state`\n",
    "- **Measure:** `COUNT(*) AS n`\n",
    "- **Present:** `ORDER BY n DESC LIMIT 15`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de45930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”§ Exercise 2.3\n",
    "sql = \"\"\"\n",
    "SELECT\n",
    "  state,\n",
    "  COUNT(*) AS n\n",
    "FROM sightings\n",
    "WHERE ...\n",
    "GROUP BY ...\n",
    "ORDER BY ...\n",
    "LIMIT ...\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    df_states = pd.read_sql_query(text(sql), conn)\n",
    "\n",
    "df_states.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f26352",
   "metadata": {},
   "source": [
    "## 3) Averages, mins/maxes, and HAVING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20dfb82",
   "metadata": {},
   "source": [
    "Weâ€™ll use the numeric column `` `duration (seconds)` `` and compute summaries by group. Use `HAVING` to filter **after** aggregation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d04847",
   "metadata": {},
   "source": [
    "### RQ 4 â€” Which shapes tend to have longer reported durations?\n",
    "**Question.** *For each shape, what is the average reported `duration (seconds)`? Consider only shapes with enough data.*\n",
    "\n",
    "**Translate â†’ SQL.**\n",
    "- **Group:** by `shape`\n",
    "- **Measure:** `AVG(\\`duration (seconds)\\`) AS avg_seconds`, plus `COUNT(*) AS n`\n",
    "- **Quality filter:** `HAVING n >= 30`\n",
    "- **Present:** `ORDER BY avg_seconds DESC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e1182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”§ Exercise 3.1\n",
    "sql = \"\"\"\n",
    "SELECT\n",
    "  shape,\n",
    "  AVG(`duration (seconds)`) AS avg_seconds,\n",
    "  COUNT(*)                  AS n\n",
    "FROM sightings\n",
    "GROUP BY ...\n",
    "HAVING ...\n",
    "ORDER BY ...\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    df_avg_shape = pd.read_sql_query(text(sql), conn)\n",
    "\n",
    "df_avg_shape.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8118b7c",
   "metadata": {},
   "source": [
    "### RQ 5 â€” How spread out are durations within each shape?\n",
    "**Question.** *What are the min/max durations by shape, and a rounded average?*\n",
    "\n",
    "**Translate â†’ SQL.**\n",
    "- **Group:** by `shape`\n",
    "- **Measures:** `MIN`, `MAX`, `ROUND(AVG(...), 1)`, `COUNT(*) AS n`\n",
    "- **Quality filter:** keep only groups with enough records if needed (e.g., `HAVING n >= 30`)\n",
    "- **Present:** sort by `n` or by `avg_s_rounded` as useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a846028e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”§ Exercise 3.2\n",
    "sql = \"\"\"\n",
    "SELECT\n",
    "  shape,\n",
    "  MIN(`duration (seconds)`)              AS min_s,\n",
    "  MAX(`duration (seconds)`)              AS max_s,\n",
    "  ROUND(AVG(`duration (seconds)`), 1)    AS avg_s_rounded,\n",
    "  COUNT(*)                               AS n\n",
    "FROM sightings\n",
    "GROUP BY ...\n",
    "HAVING ...\n",
    "ORDER BY ...\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    df_minmax = pd.read_sql_query(text(sql), conn)\n",
    "\n",
    "df_minmax.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa63f5d6",
   "metadata": {},
   "source": [
    "## 4) Handling NULL/empty and simple string helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef682e10",
   "metadata": {},
   "source": [
    "We'll group on a **filled** state value using `COALESCE`. Example pattern:\n",
    "\n",
    "```sql\n",
    "COALESCE(NULLIF(TRIM(state), ''), 'UNKNOWN')\n",
    "```\n",
    "\n",
    "That treats whitespace/empty strings as NULL and replaces missing with `'UNKNOWN'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bda67a",
   "metadata": {},
   "source": [
    "### RQ 6 â€” How many U.S. reports have missing/blank states?\n",
    "**Question.** *Count U.S. sightings by state, but put missing/blank ones into an `UNKNOWN` bucket.*\n",
    "\n",
    "**Translate â†’ SQL.**\n",
    "- **Row filter:** `WHERE country = 'us'`\n",
    "- **Grouping key:** `COALESCE(NULLIF(TRIM(state), ''), 'UNKNOWN')`\n",
    "- **Measure:** `COUNT(*) AS n`\n",
    "- **Present:** `ORDER BY n DESC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681aa6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”§ Exercise 4.1\n",
    "sql = \"\"\"\n",
    "SELECT\n",
    "  COALESCE(NULLIF(TRIM(state), ''), 'UNKNOWN') AS state_bucket,\n",
    "  COUNT(*) AS n\n",
    "FROM sightings\n",
    "WHERE country = 'us'\n",
    "GROUP BY ...\n",
    "ORDER BY ...\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    df_state_bucket = pd.read_sql_query(text(sql), conn)\n",
    "\n",
    "df_state_bucket.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da52d269",
   "metadata": {},
   "source": [
    "## 5) Light date/time derived columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc3a237",
   "metadata": {},
   "source": [
    "The `datetime` column is stored as text in the form `MM/DD/YYYY HH:MM`. MySQL can parse it with `STR_TO_DATE`.\n",
    "We'll extract **year** to see longâ€‘term patterns.\n",
    "\n",
    "Format string: `'%m/%d/%Y %H:%i'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fed07e",
   "metadata": {},
   "source": [
    "### RQ 7 â€” Which years were the busiest for reports?\n",
    "**Question.** *How many sightings were logged each year?*\n",
    "\n",
    "**Translate â†’ SQL.**\n",
    "- **Derived year:** `YEAR(STR_TO_DATE(\\`datetime\\`, '%m/%d/%Y %H:%i')) AS yr`\n",
    "- **Group:** by `yr`\n",
    "- **Measure:** `COUNT(*) AS n`\n",
    "- **Present:** sort by `n` desc; show top 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63e38ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”§ Exercise 5.1\n",
    "sql = \"\"\"\n",
    "SELECT\n",
    "  YEAR(STR_TO_DATE(`datetime`, '%m/%d/%Y %H:%i')) AS yr,\n",
    "  COUNT(*) AS n\n",
    "FROM sightings\n",
    "GROUP BY ...\n",
    "ORDER BY ...\n",
    "LIMIT ...\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    df_years = pd.read_sql_query(text(sql), conn)\n",
    "\n",
    "df_years.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89bc1b8",
   "metadata": {},
   "source": [
    "**ðŸ“ Interpretation (1â€“2 sentences).** In plain English, answer the research question above based on your result. \n",
    "\n",
    "- Mention any pattern or outlier you see.\n",
    "- If relevant, note one limitation (e.g., small group sizes, missing data).\n",
    "\n",
    "*Type your short answer here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08025886",
   "metadata": {},
   "source": [
    "### RQ 8 â€” Does average reported duration change over time?\n",
    "**Question.** *For each year with at least 100 reports, what is the average duration?*\n",
    "\n",
    "**Translate â†’ SQL.**\n",
    "- **Derived year:** same `yr` expression as above\n",
    "- **Group:** by `yr`\n",
    "- **Measures:** `AVG(\\`duration (seconds)\\`) AS avg_seconds`, `COUNT(*) AS n`\n",
    "- **Quality filter:** `HAVING n >= 100`\n",
    "- **Present:** `ORDER BY yr ASC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae836e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”§ Exercise 5.2\n",
    "sql = \"\"\"\n",
    "SELECT\n",
    "  YEAR(STR_TO_DATE(`datetime`, '%m/%d/%Y %H:%i')) AS yr,\n",
    "  AVG(`duration (seconds)`) AS avg_seconds,\n",
    "  COUNT(*) AS n\n",
    "FROM sightings\n",
    "GROUP BY ...\n",
    "HAVING ...\n",
    "ORDER BY ...\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    df_avg_by_year = pd.read_sql_query(text(sql), conn)\n",
    "\n",
    "df_avg_by_year.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b92b7c",
   "metadata": {},
   "source": [
    "## 6) Light pandas (inspect + simple viz)\n",
    "\n",
    "**RQ 2 (visual):** *Which shapes get reported the most?* Make a quick bar chart of your top 10 shapes result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137ff005",
   "metadata": {},
   "source": [
    "We'll keep pandas simple. Convert one of your SQL results into a small **bar chart**.\n",
    "\n",
    "> If plotting causes issues, skip the plot and just show the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3342ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of top shapes (from Exercise 2.2)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_shapes_plot = df_shapes.copy().head(10)\n",
    "df_shapes_plot.plot(kind=\"bar\", x=\"shape\", y=\"n\", legend=False, title=\"Top 10 UFO shapes by count\")\n",
    "plt.xlabel(\"shape\"); plt.ylabel(\"count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7611232",
   "metadata": {},
   "source": [
    "## (Optional) Fallback: local CSV (pandas only)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11842979",
   "metadata": {},
   "source": [
    "If you need to test without a DB connection, you can upload `ufo_scrubbed.csv` and practice the pandas parts.\n",
    "This does **not** replace the requirement to connect to the database for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380e9019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "try:\n",
    "    from google.colab import files\n",
    "    print(\"Upload ufo_scrubbed.csv\")\n",
    "    uploaded = files.upload()\n",
    "    csv_name = next(iter(uploaded.keys()))\n",
    "    ufo_csv = pd.read_csv(csv_name)\n",
    "    ufo_csv.head()\n",
    "except Exception as e:\n",
    "    print(\"Upload not available here:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec47ff83",
   "metadata": {},
   "source": [
    "## Troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6bf2d2",
   "metadata": {},
   "source": [
    "- **`Access denied ...` (1045)** â†’ Check your readâ€‘only username/password and ask the instructor if needed.\n",
    "- **Timeout / canâ€™t connect (2003)** â†’ Network or RDS SG issue. Try campus Wiâ€‘Fi or VPN; ask the instructor to whitelist your IP if necessary.\n",
    "- **`ssl ca certificate` errors** â†’ Reâ€‘run the PEM download cell or upload the correct `global-bundle.pem` and ensure `connect_args={\"ssl_ca\": \"global-bundle.pem\"}`.\n",
    "- **SQL errors** â†’ Check backticks around columns with spaces or punctuation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa696b0",
   "metadata": {},
   "source": [
    "## Submit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49008014",
   "metadata": {},
   "source": [
    "- **Runtime â†’ Restart and run all** to confirm a clean run\n",
    "- **File â†’ Download .ipynb**, rename to `Notebook2_LastFirst.ipynb`, and submit as directed"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
